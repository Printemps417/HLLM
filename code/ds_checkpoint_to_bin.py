import os
import sys
import torch
import subprocess
from transformers import AutoModelForCausalLM, AutoConfig

# ---------------------- é…ç½®å‚æ•°ï¼ˆå¿…é¡»ä¿®æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„ï¼ï¼‰----------------------
DS_CHECKPOINT_DIR = "/root/autodl-tmp/HLLM/saved_model/HLLM-0.pth/checkpoint" 
CONFIG_FILE_PATH = "/root/autodl-tmp/HLLM/pretrained_models/Qwen3-0.6B-FP8/config.json"
# 3. æœ€ç»ˆè¾“å‡ºç›®å½•ï¼ˆç”Ÿæˆ pytorch_model.bin å’Œ config.jsonï¼‰
OUTPUT_DIR = "/root/autodl-tmp/HLLM/pretrained_models/Qwen3-0.6B-FP8/inferred_model"
# 4. ä¸´æ—¶æ–‡ä»¶ç›®å½•ï¼ˆåˆå¹¶åçš„ä¸­é—´ .pt æ–‡ä»¶ï¼Œè½¬æ¢å®Œæˆåä¼šè‡ªåŠ¨åˆ é™¤ï¼‰
TEMP_MERGED_FILE = "./temp_merged_model.pt"
# 5. DeepSpeed zero_to_fp32.py è„šæœ¬è·¯å¾„ï¼ˆå½“å‰ç›®å½•ä¸‹å°±æœ‰ï¼Œæ— éœ€ä¿®æ”¹ï¼‰
ZERO_TO_FP32_SCRIPT = "/root/autodl-tmp/HLLM/saved_model/HLLM-0.pth/zero_to_fp32.py"
# --------------------------------------------------------------------------------

def check_file_exists(file_path):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™é€€å‡º"""
    if not os.path.exists(file_path):
        print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶/ç›®å½• {file_path} ä¸å­˜åœ¨ï¼")
        sys.exit(1)

def merge_deepspeed_checkpoint(ds_checkpoint_dir, output_merged_file, zero_script):
    """ç¬¬ä¸€æ­¥ï¼šç”¨ DeepSpeed è„šæœ¬åˆå¹¶åˆ†å¸ƒå¼ checkpoint"""
    print("="*50)
    print("âœ… å¼€å§‹åˆå¹¶ DeepSpeed åˆ†å¸ƒå¼ checkpoint...")
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    check_file_exists(ds_checkpoint_dir)
    check_file_exists(zero_script)
    
    # æ„å»ºåˆå¹¶å‘½ä»¤ï¼ˆè°ƒç”¨ zero_to_fp32.pyï¼‰
    cmd = [
        sys.executable,  # ä½¿ç”¨å½“å‰ Python ç¯å¢ƒ
        zero_script,
        ds_checkpoint_dir,
        output_merged_file
    ]
    
    try:
        # æ‰§è¡Œåˆå¹¶å‘½ä»¤
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
        print("âœ… DeepSpeed checkpoint åˆå¹¶æˆåŠŸï¼")
        print(f"âœ… ä¸­é—´åˆå¹¶æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{output_merged_file}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ DeepSpeed checkpoint åˆå¹¶å¤±è´¥ï¼é”™è¯¯ä¿¡æ¯ï¼š{e.stderr}")
        sys.exit(1)

def convert_merged_pt_to_hf_bin(merged_pt_file, config_path, output_dir):
    """ç¬¬äºŒæ­¥ï¼šå°†åˆå¹¶åçš„ .pt æ–‡ä»¶è½¬æˆ Hugging Face pytorch_model.bin"""
    print("="*50)
    print("âœ… å¼€å§‹è½¬æ¢ä¸º Hugging Face æ ‡å‡†æ ¼å¼...")
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    check_file_exists(merged_pt_file)
    check_file_exists(config_path)
    
    # 1. åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # 2. åŠ è½½æ¨¡å‹é…ç½®
    print("âœ… åŠ è½½æ¨¡å‹é…ç½®...")
    config = AutoConfig.from_pretrained(config_path)
    
    # 3. åˆå§‹åŒ–ç©ºæ¨¡å‹ï¼ˆæŒ‰é…ç½®åˆ›å»ºæ¶æ„ï¼‰
    print("âœ… åˆå§‹åŒ–ç©ºæ¨¡å‹æ¶æ„...")
    model = AutoModelForCausalLM.from_config(config)
    
    # 4. åŠ è½½åˆå¹¶åçš„ .pt æƒé‡ï¼ˆåŠ è½½åˆ° CPUï¼Œé¿å…æ˜¾å­˜ä¸è¶³ï¼‰
    print("âœ… åŠ è½½åˆå¹¶åçš„ .pt æƒé‡æ–‡ä»¶...")
    pt_weights = torch.load(merged_pt_file, map_location="cpu")
    
    # 5. å¤„ç†æƒé‡æ ¼å¼ï¼ˆæ¸…ç†å†—ä½™å‰ç¼€ã€æå– model_state_dictï¼‰
    print("âœ… æ¸…ç†å¹¶åŒ¹é…æƒé‡æ ¼å¼...")
    # æå– model_state_dictï¼ˆå¦‚æœæœ‰åµŒå¥—ï¼‰
    if "model_state_dict" in pt_weights:
        model_weights = pt_weights["model_state_dict"]
    else:
        model_weights = pt_weights
    
    # ç§»é™¤ module. å‰ç¼€ï¼ˆDeepSpeed åˆ†å¸ƒå¼è®­ç»ƒå¯èƒ½æ·»åŠ ï¼‰
    cleaned_weights = {}
    for key, value in model_weights.items():
        new_key = key[len("module."):] if key.startswith("module.") else key
        cleaned_weights[new_key] = value
    
    # 6. åŠ è½½æƒé‡åˆ°æ¨¡å‹
    try:
        model.load_state_dict(cleaned_weights, strict=False)  # strict=False å…¼å®¹éƒ¨åˆ†éæ ¸å¿ƒæƒé‡ä¸åŒ¹é…
        print("âœ… æƒé‡æˆåŠŸåŠ è½½åˆ°æ¨¡å‹ï¼Œæ ¼å¼åŒ¹é…ï¼")
    except Exception as e:
        print(f"âš ï¸  æƒé‡éƒ¨åˆ†ä¸åŒ¹é…ï¼ˆéè‡´å‘½ï¼Œå¯ç»§ç»­ï¼‰ï¼š{e}")
    
    # 7. ä¿å­˜ä¸º Hugging Face æ ‡å‡†æ ¼å¼ï¼ˆpytorch_model.binï¼‰
    print("âœ… ä¿å­˜ä¸º pytorch_model.bin...")
    model.save_pretrained(
        output_dir,
        save_config=True,  # è‡ªåŠ¨å¤åˆ¶ config.json åˆ°è¾“å‡ºç›®å½•
        safe_serialization=False  # ä¿å­˜ä¸º pytorch_model.binï¼ˆTrue åˆ™ä¿å­˜ä¸º safetensors æ ¼å¼ï¼‰
    )
    
    print(f"âœ… Hugging Face æ ¼å¼æ¨¡å‹ä¿å­˜å®Œæˆï¼ç›®å½•ï¼š{output_dir}")
    return True

def clean_temp_file(temp_file):
    """åˆ é™¤ä¸´æ—¶åˆå¹¶æ–‡ä»¶ï¼Œæ¸…ç†ç£ç›˜ç©ºé—´"""
    if os.path.exists(temp_file):
        os.remove(temp_file)
        print("="*50)
        print(f"âœ… å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼š{temp_file}")

def main():
    """ä¸»æµç¨‹ï¼šåˆå¹¶ â†’ è½¬æ¢ â†’ æ¸…ç†"""
    try:
        # ç¬¬ä¸€æ­¥ï¼šåˆå¹¶ DeepSpeed checkpoint
        merge_success = merge_deepspeed_checkpoint(
            DS_CHECKPOINT_DIR,
            TEMP_MERGED_FILE,
            ZERO_TO_FP32_SCRIPT
        )
        
        if not merge_success:
            sys.exit(1)
        
        # ç¬¬äºŒæ­¥ï¼šè½¬æ¢ä¸º pytorch_model.bin
        convert_success = convert_merged_pt_to_hf_bin(
            TEMP_MERGED_FILE,
            CONFIG_FILE_PATH,
            OUTPUT_DIR
        )
        
        if not convert_success:
            sys.exit(1)
        
    finally:
        # ç¬¬ä¸‰æ­¥ï¼šæ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆæ— è®ºæˆåŠŸä¸å¦ï¼Œéƒ½åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼‰
        clean_temp_file(TEMP_MERGED_FILE)
    
    print("="*50)
    print("ğŸ‰ ä¸€é”®è½¬æ¢å…¨éƒ¨å®Œæˆï¼æœ€ç»ˆæ–‡ä»¶åœ¨ï¼š", OUTPUT_DIR)
    print(f"ğŸ‰ å¯é€šè¿‡ AutoModelForCausalLM.from_pretrained('{OUTPUT_DIR}') åŠ è½½ä½¿ç”¨")

if __name__ == "__main__":
    main()